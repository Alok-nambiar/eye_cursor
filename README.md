# ğŸ‘ï¸ EyeCursor â€“ Eye Tracking Based Cursor Control System

EyeCursor is a real-time eye trackingâ€“based desktop application that enables hands-free cursor control using a webcam and offline voice commands.  
The system is designed as an assistive technology and a humanâ€“computer interaction project, focusing on accuracy, stability, and usability.

---

## ğŸš€ Features

- ğŸ¥ **Live Camera Feed**
  - Real-time eye detection and gaze tracking
  - Smooth cursor movement with reduced jitter

- ğŸ¯ **Calibration Module**
  - User-specific gaze calibration
  - Improves screen-wide cursor accuracy

- âš™ï¸ **Settings Panel**
  - Adjustable sensitivity and smoothing parameters
  - UI customization options

- ğŸ“œ **Logs Section**
  - System activity and event logging
  - Helpful for debugging and analysis

- ğŸ‘ï¸ **Blink Detection**
  - Detects eye blinks for interaction control
  - Can be extended to support click actions

- ğŸ§  **Gaze Tracking & Smoothing**
  - Kalman filterâ€“based smoothing
  - Eliminates sudden jumps and noise

- ğŸ™ï¸ **Offline Voice Control**
  - Uses Vosk speech recognition
  - Works without internet connection

---

## ğŸ› ï¸ Tech Stack

- **Language:** Python  
- **Computer Vision:** OpenCV  
- **Eye Tracking:** Custom gaze estimation logic  
- **Speech Recognition:** Vosk (offline)  
- **UI:** Python-based graphical interface  
- **Filtering:** Kalman Filter  
- **Libraries:** NumPy, PyAutoGUI  

---

## ğŸ“‚ Project Structure

```text
EyeCursor/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main_with_ui.py        # Main entry point (RUN THIS FILE)
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ gaze_tracker.py
â”‚   â”œâ”€â”€ blink_detection.py
â”‚   â”œâ”€â”€ calibration.py
â”‚   â”œâ”€â”€ kalman_filter.py
â”‚   â”œâ”€â”€ smoothing.py
â”‚   â”œâ”€â”€ voice_listener.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â”œâ”€â”€ ui_settings.json
â”‚   â”œâ”€â”€ calibration_data.json
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ vosk-model-small-en-us-0.15/
â”‚
â”œâ”€â”€ docs/
â”œâ”€â”€ tests/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```
---

## â–¶ï¸ How to Run the Project
```bash
### 1ï¸âƒ£ Clone the Repository

git clone https://github.com/ChikkannaS/EyeCursor.git
cd EyeCursor
2ï¸âƒ£ Create Virtual Environment (Recommended)
bash
Copy code
python -m venv venv
venv\Scripts\activate
3ï¸âƒ£ Install Dependencies
bash
Copy code
pip install -r requirements.txt
4ï¸âƒ£ Run the Application
bash
Copy code
python src/main_with_ui.py
```
---

## ğŸ–¥ï¸ Application Workflow
Running main_with_ui.py launches the EyeCursor UI

The UI contains four main sections:

Camera Feed â€“ Displays live eye tracking

Calibration â€“ Calibrates gaze for the user

Settings â€“ Adjusts sensitivity and smoothing

Logs â€“ Shows system events and status

Cursor movement is controlled using eye gaze

Voice commands provide additional control options

---

## ğŸ§ª Use Cases

- Hands-free computer control
- Assistive technology for accessibility
- Humanâ€“computer interaction research
- Academic and learning projects

---

## ğŸ“¸ Screenshots

### Main UI
![Main UI](screenshots/main_ui.png)

### Calibration Screen
![Calibration Screen](screenshots/calibration_screen.png)

---

## ğŸ”® Future Enhancements

- Blink-based click actions
- Multi-monitor support
- MediaPipe-based gaze estimation
- AI-driven personalization
- Performance optimization

---

## ğŸ“ Academic & Placement Note

This project was developed as a **college academic project** and demonstrates:

- Real-time computer vision
- Modular Python architecture
- Signal smoothing and filtering
- Offline AI integration
